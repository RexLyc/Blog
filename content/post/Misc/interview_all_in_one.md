---
title: "面试总结：大全篇"
date: 2023-02-11T22:15:25+08:00
categories:
- 求职面试
tags:
- 求职面试
- 施工中
thumbnailImagePosition: left
thumbnailImage: /images/thumbnail/interview.jpg
---
这篇笔记总结历次求职面试的经历，对笔试、面试题目进行总结，也会对非专业考察内容进行一定的梳理。
<!--more-->
## 整体准备
1. 心理：
    - 放松心态
    - 先思考整体，理清几个要点和思路，再谨慎答题
    - 提前准备几个问考官的问题
1. 行为面试：简短介绍自己（因为已经有简历了），项目经验介绍STAR（背景，完成的任务，做了哪些工作，自己的贡献），跳槽原因（和自己的发展目标不符，而目标公司符合）
1. 技术面试：正确、鲁棒的高质量代码（鲁棒非常重要，一定要保证不能崩溃），软技能（沟通和学习能力）。 不要怕问问题，多问一些限制条件。 在不需要考虑栈上消耗的情况下，适当使用递归减少编程量。
## 专业性考察
### C/C++：
1. 类型的最小大小？
  - 空类型的sizeof是1（和编译器有关，但是必须在内存中占有一定空间）。添加普通构造和析构函数，仍是1。添加虚析构，占用计算机位长（e.g.8字节，原因：虚函数表，虚函数表指针）
2. 复制构造是否可以传值？
  - 复制构造函数不允许是传值函数。传值会导致无限复制构造。
3. 写一个赋值运算符函数？
  - 4个要点：返回引用，参数是常量引用，释放旧空间，预先检查是否是自己。异常安全性问题（凡是new的时候都要考虑）。多线程安全问题。[常见运算符重载](https://www.runoob.com/cplusplus/cpp-overloading.html)
4. sizeof的值？
  - 数组：数组总长（字节数）
  - 指针：计算机字长（字节数）
  - 数组形参：退化为指针，仍然是计算机字长（字节数）
5. char a[]="hello"，sizeof(a)=?
  - 6，字符串字面值结尾会自动添加"\0"
6. char (\*p)[5]和char\* p[5]的区别？
  - 根据括号优先原则，前者是一个数组指针，指向char[5]，后者是一个指针数组
7. 引用和指针什么时候不能互换？说一下二者区别
  - 引用是一个别名，必须在定义处进行初始化。而指针是一个变量，可以有控制，可以被修改
  - 引用只有一级，指针可以有多级
  - 在const、sizeof、自增自减运算符等使用上均有不同的意义
8. C++三种时钟的使用区别？
  - steady_clock是启动时间，不可修改，high_resolution_clock是高精度时钟，system_clock是系统时间
9. 什么是RAII？
  - Resource Acquisition Is Initialization,也称为“资源获取就是初始化”
10. 类中static成员的初始化时间
  - 在程序启动时
11. 什么是返回值优化RVO、NRVO？
  - 是一项编译期优化技术，主要是为了消除函数返回值创建的临时对象。RVO是匿名变量优化，NRVO是具名局部变量优化
  - 当满足优化条件的函数返回一个对象时，RVO和NRVO会消除掉临时变量的构造，以及赋值时产生的复制构造，直接在外部调用处进行一次构造
  - 函数返回值不应当使用std::move，这样会导致无法进行RVO、NRVO优化，性能更低
12. static_cast、dynamic_cast、const_cast、reinterpret_cast区别？
  - 分别主要用于静态强转（类似C的转换）、类型继承关系内的下行转换、移除const、指针转换
13. make_shared和传递裸指针给shared_ptr的区别？
  - make_shared更安全，而且由于make_shared是统一的一次内存分配，shared_ptr实际上是两次内存分配，使用make_shared，智能指针和实际对象会存储在相近的位置。
14. 构造函数中能否调用虚函数？
  - 可以调用虚函数，但是仍然会视为普通函数，类在构造构成中尚未建立虚函数表，不具备动态绑定能力，只会调用本类已具有的函数
15. short i=65537;此时i的值是？
  - 字面值默认是int，而且向下赋值的时候进行截断，所以i的值是1，而不是负数
16. 以下代码
  ```cpp
  class A {public:virtual void a() {}};
  class B {public:virtual void a() {}};
  class C:public A,public B {public:virtual void a() {}};
  C obj;

  A* pA = &obj;
  B* pB = &obj;
  C* pC = &obj;
  
  // 值是否相等
  cout << pA << endl;
  cout << pB << endl;
  cout << pC << endl;
  ```
  - 多继承的派生类指针向基类转型时，会丢掉其虚表中，在继承时顺序位于当前基类之前的其他基类的虚表内容。因此pA和pC相等、而pB和pA、pC不相等。
17. C++的多态有哪些
  - 静态多态：模板、重载函数
  - 动态多态：虚函数
18. 为什么要引入右值引用：
  - 主要是为了解决两件事情（完美转发、移动语义）
19. 如何实现auto？
  - 个人理解是编译期解析等号右侧、函数返回值的类型，并去除其中的const、&、volatile
20. unique_ptr为什么必shared_ptr快？
  - unique_ptr没有引用计数，在构造、析构、实用时都没有这方面的访存需求；shared_ptr存在一个原子引用计数需要维护
### Java-Spring
1. 压测如何分析性能？
    - 使用系统分析器，例如linux的perf，可以分析系统性能
    - JVM分析器，例如hprof，jprofiler，也可以用jdk自带的工具，如jstack、jmap、jstat、jcmd，以及JMX、JFR等工具。
1. CMS和G1的区别
    - 参考[JVM收集器CMS与G1区别和优缺点分析](https://juejin.cn/post/6975890045060251678)、[这三大特性让G1取代了CMS](https://www.51cto.com/article/717309.html)
    - G1（标记整理）相比于CMS（标记清除），使用了分Region的思想，并不再将分代内存连续分配（可以eden、survivor、old乱序相邻），衡量回收内存效益最大的Region，以在回收时达到控制GC停顿时间的目的（目标是可预测的停顿时间，相比之下CMS扫描整个老年代）
    - CMS会产生内存碎片，而G1不会
    - CMS只针对老年代、G1对新生代和老年代都有效
    - CMS对CPU敏感
1. 过滤器、拦截器、AOP的区别和使用场景
  - Tomcat容器提供的处理顺序是：filter、servlet、interceptor、controller
  - 过滤器的实现基于回调函数，过滤器是JavaEE标准、也是Servlet容器规范的一部分，由servlet进行回调。
  - 拦截器可以拦截IOC容器中的各个bean，拦截器是Spring提供并管理的，是通过反射实现的。拦截器依赖于SpringMVC的，需要有mvc的依赖。
  - 过滤器和拦截器的区别简单来说：生效时间不同、过滤器可以修改request、过滤器只能在servlet中实现、拦截器可以在任何spring支持的环境中。
  - 三者在拦截能力上的区别
    - 过滤器并没有定义业务用于执行逻辑前、后等，仅仅是请求到达就执行。
    - 拦截器有三个方法，相对于过滤器更加细致，有被拦截逻辑执行前、后等。
    - AOP针对具体的代码，能够实现更加复杂的业务逻辑。
  - 更多细节参考[博客园](https://www.cnblogs.com/itlihao/p/14329905.html)
2. @Autowired的替换品
  - 使用@Resource替换，或者使用@RequiredArgsConstructor构造器方式注入。不推荐Autowired的主要原因是属性注入会有一些问题。首先是在构造器中注入未完成，无法使用；其次是添加注解太简单会导致某个类异常庞大，说明设计上有所欠缺；属性注解会造成类不能通过反射创建，必须强依赖容器，在spring容器之外无法使用。
  - 推荐用法就是强制依赖就用构造器方式，可选、可变的依赖就用setter注入
  - 参考[@Autowired依赖注入为啥不推荐了](https://cloud.tencent.com/developer/article/2097943)
3. JVM大对象分配位置，如果survivor区不够了怎么办，什么是分配担保
  - 受GC算法影响，在Parallel New和Serial中有参数-XX:PretenureSizeThreshold，超过的大对象将直接分配在老年代
  - survivor区不够了由老年代进行分配担保，即将超出的存活对象，移动到老年代
  - 分配担保是MinorGC和FullGC进行取舍时的一个概念，如果GC前发现新生代的已用内存总数大于老年代剩余连续空闲内存，那么这一次GC是有风险的，如果存在需要分配担保的情况，将数据移动到老年代，老年代也可能发生空间不足。因此在这种情况下，可能会使用FullGC来确保空间足够。
1. Springboot和Spring，和Java传统web开发有什么区别？
  - 参考[Spring Boot 简介？与传统的 Spring 框架有何不同？](https://zhuanlan.zhihu.com/p/631533884)、[javaweb、spring、springmvc和springboot有什么区别？](https://cloud.tencent.com/developer/news/991283)
### 网络
1. IP协议的主要功能？
    - 定义了在TCP/IP 互联网上数据传送的基本单元。为克服数据链路层最大帧长的限制，提供数据分段和重组的功能。
    - 提供用于寻址的标志，寻找网络中每个主机，完成路由选择功能。
    - 包含了不可靠分组传送的规则，指明分组处理、差错信息发生以及分组丢弃等规则
2. 什么是流量控制和拥塞避免？
    - 流量控制是用发送、接收窗口进行控制，目的是防止接收方处理数据不及时造成丢包
    - 拥塞避免是TCP发送包时，对网络环境的一种考虑，保持分组以合理的速度进入网络，避免网络中的某一段出现拥塞而丢失报文
3. TCP的可靠性是如何保证的？
    - 连接时的三次握手、超时重发、流量控制和接收发送滑动窗口、拥塞控制（慢启动、拥塞避免、快重传和快恢复）
4. 如何优化TCP连接的大量TIME_WAIT状态？
    - 优化内核参数：允许TIME_WAIT状态套接字直接用于新TCP连接，快速回收TIME_WAIT套接字，缩短MSL超时时间，减少允许处于TIME_WAIT的套接字数量、增加可用端口范围
    - 在系统的各个部分连接中，尽量使用长连接（客户端-网关-后端）
5. 负载均衡的底层实现？
    - 在数据链路层：通过伪MAC地址接收，再分发给实际MAC
    - 在网络层：通过伪IP接收，再分发给实际IP
    - 在传输层：伪（IP+端口），再分发
    - 在业务层：使用虚拟URL，再分发给不通的业务主机
6. 什么是I/O多路复用？有哪些？应用场景
  - IO 多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄。一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作。没有文件句柄就绪就会阻塞应用程序，交出CPU。
  - 使用I/O多路复用是为了解决BIO（同步阻塞）、NIO（这里指轮询查询的方式，同步非阻塞）的问题。
  - select：需要轮询提交的所有I/O事件表中是否有可用的。poll和select没有本质区别，只是没有了最大表的限制（和文件一致为65535），采用链表实现。这两都是轮询。他们每一次需要将希望监听的I/O事件，从用户空间提交到内核空间。内核轮询所有的I/O事件，返回可用的。从这一点上来看是O(n)的。
  - epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。epoll也只在每一次最初提交的时候，才会将等待的I/O事件，从用户空间拷贝到内核空间。每次回调也是直接发起（复杂度降低到了O(1)）。
  - 目前Redis是使用epoll的I/O多路复用，Netty根据使用场景（受JDK和系统限制），分别有select/poll/epoll的实现。
  - 参考[彻底理解IO多路复用实现机制](https://juejin.cn/post/6882984260672847879)
7. Reactor和Proactor的区别？
  - 和I/O多路复用相关。在 Reactor 模式中，Reactor 等待某个事件或者可应用或者操作的状态发生（比如文件描述符可读写，或者是 Socket 可读写）。然后把这个事件传给事先注册的 Handler（事件处理函数或者回调函数），由后者来做实际的读写操作。其中的读写操作都需要应用程序同步操作，所以 Reactor 是非阻塞同步网络模型。如果把 I/O 操作改为异步，即交给操作系统来完成就能进一步提升性能，这就是异步网络模型 Proactor。
  - 参考[Linux高性能IO网络模型对比分析：Reactor vs Proactor](https://cloud.tencent.com/developer/article/1769945)
1. 除了三次握手和四次挥手，TCP还有别的连接和断开方式吗？
  - 在连接和断开时，如果双方都在很短事件内同时发起连接、发起断开连接，则有同时打开和同时关闭，两种特殊的连接和断开模式。此时是四次握手，但仍是四次挥手。状态机也都是镜像的分别是SYNC_SENT、SYNC_RECV、ESTABLISHED。和FIN_WAIT_1、CLOSING、TIME_WAIT。
  - 参考[TCP状态转换图总结](https://zhuanlan.zhihu.com/p/78540103)、[计算机网络：TCP同时打开和同时关闭](https://www.jianshu.com/p/aea9ae5c8a3c)
### 分布式
1. 什么是CAP、BASE
  - CAP定理指一个分布式系统，最多只能同事满足C（Consistency）一致性、A（Availability）可用性、P（Partition Tolerance）分区容错性中的两个。对于大多数系统来说，P是必须保证的（网络分区发生时，系统能继续运行），所以需要在C和A之间取舍。例如zk和etcd侧重CP，eureka是去中心化的对等节点所以侧重AP
  - BASE理论是CAP的一个发展，对C和A进行权衡的结果，Basically Availability基本可用，Soft State软状态（允许数据存在中间状态，但不影响可用性），Eventually Consistent最终一致性（经过一段时间一定能达到一致）。
  - 对最终一致性的保证通常有三种方式：读时修复（读取时发现数据不一致就进行修复）、写时修复（写失败定时重写）、异步修复（常用，定时检测副本一致性）
2. 说说服务发现和负载均衡机制的实现？
  - 参考[技术文章摘抄-服务治理](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Netty%20%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%E4%B8%8E%20RPC%20%E5%AE%9E%E8%B7%B5-%E5%AE%8C/26%20%20%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%EF%BC%9A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%9A%84%E5%AE%9E%E7%8E%B0.md)
  - 在微服务架构中的负载均衡是指服务消费者在发起 RPC 调用之前，需要感知有多少服务端节点可用，然后从中选取一个进行调用。有多种负载均衡策略，Round-Robin 轮询、Weighted Round-Robin 权重轮询、Least Connections 最少连接数、Consistent Hash 一致性 Hash 等。这里以[一致性Hash](https://www.xiaolincoding.com/os/8_network_system/hash.html)为例。服务器可以选择 IP + Port 进行 Hash。所谓的一致哈希，就是使用了更大的模（比如2^32），这样所有的节点（消费者和生产者）都位于一个环上。每个消费者寻找在环上的下一个服务器即可。同时为了更好的均衡各个服务器之间的连接数量，还会在哈希环上添加若干虚拟服务节点（比如一个物理节点扩充3个虚拟节点），来避免不均衡。
  > 不使用普通哈希是因为，普通的哈希，如果模数就是节点数的话，一旦服务器节点数量变化，连接全部会断，最糟糕的情况下会发生数据迁移。降低了性能
1. 分布式事务有哪些实现方式？
  - 2PC：两阶段事务，事务准备和事务提交，事务协调者询问所有资源提供者，能否进行某个事务，得到肯定后开始向所有资源提供者发起提交。问题是在准备期长时间锁定资源、协调者单点故障可能导致事务永久上锁、第二阶段可能出现某次rollback/commit失败导致数据不一致。
  - 3PC：三阶段事务。协调者和参与者引入超时机制。并将准备阶段进一步细分为，canCommit（是否具备执行事务）和preCommit阶段。但是仍然有第三阶段rollback部分节点未收到的数据不一致问题。
  - XA：XA 协议是由 X/Open 组织提出的基于2PC、3PC模式的分布式事务处理规范。规范了术语，AP应用程序、TM事务管理器、RM资源管理器、CRM通信资源管理器如中间件。
  - TCC：Try-Confirm-Cancel，TCC是基于BASE理论。XA的两阶段提交是基于资源层面的，而 TCC 也是一种两阶段提交，但它是基于应用层面的。业务服务需要提供try、confirm、cancel，业务侵入性强。而且confirm、cancel必须做幂等接口，以防止重复操作问题。由于是业务实现，每个Try都是业务独立完成本地事务，因此不会对资源一直加锁。
  - 参考[分布式事务笔记(XA,TCC,Saga)](https://www.vimiix.com/posts/2021-12-21-learn-distributed-transaction/)
2. 秒杀系统中的超卖问题如何解决
  - 基本的思路就是通过层层限流（要尽量保证公平，根据用户信息做风控），保证最后只有少量请求能真正拿到令牌，进入到尝试读写库的环境
  - 将库存数据前移，分散到多个redis中，下单时预减库存，并配合延迟消息队列，判断是否支付以决定是否需要恢复库存。使用redis提供的锁（set指令），对redis内的库存数据进行扣减，扣减成功的才能提交订单到MySQL和消息队列中。并由下游的支付等模块继续处理。
  - 参考[电商系统如何防止超卖？ - 苏三说技术的回答 - 知乎](https://www.zhihu.com/question/402246926/answer/2453352059)、[【双十一】我教女票做秒杀](https://mp.weixin.qq.com/s/6i00Qpv9lD6PcyAZQCJbyw)
1. 分布式缓存一致性的实现方案有哪些
  - 思考一个复杂场景，主从DB、主从Redis，此时根据对数据一致性的要求，可用使用同步和异步的方式。如果要求强同步，则需要在业务中用事务完成对数据库、缓存的双写。不要求强同步，则可以在业务本地开启异步任务，刷新缓存，或者由MySQL的binlog负责异步更新缓存。
  - 术语上是：CacheAside（先写库，再删除缓存）、Read/Write Through读穿写穿（程序只和缓存代理通信，由缓存代理自行负责去数据库更新，很少用因为Redis等并不支持）、WriteBack（更少用，这里是只修改缓存为脏，由其他组件保证将数据异步写入到磁盘）
  - 参考[https://blog.csdn.net/software444/article/details/106050496](https://blog.csdn.net/software444/article/details/106050496)
### 数据库
1. 聚簇索引优势在哪儿？辅助索引为什么使用主键作为值域？
   - 由于行数据和叶子节点存储在一起，这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。
   - 辅助索引使用主键作为"指针" 而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。
2. NULL对索引的影响？
   - 以MySQL5.7版本InnoDB引擎为例，索引内可以有NULL值，此时如果使用is NULL，索引仍然可以生效，甚至在联合索引内也是可以的。但是如果使用is NOT NULL，则索引失效。
   - 对于部分数据类型来说，允许可NULL甚至比不允许要耗费更多的存储空间，因此除非有必要，所有列都应当禁止NULL，并设置默认值。
3. 普通索引和主键索引的区别？
   - 普通索引没有任何限制、值可以为空、值也可能重复
   - 主键索引必须不空、不重复，而且一个表只能有一个主键索引
4. 缓存雪崩？缓存击穿？缓存穿透？
   - 雪崩是很多key同时过期，造成海量查询到数据库。可以通过分散过期时间、热点数据不过期、设置二级缓存的方式
   - 击穿是单一key过期，但此key又有大量查询。热点数据不过期，定时更新，二级缓存，引入JVM本地缓存。
   - 穿透是大量非法数据查询抵达数据库，使用布隆过滤器比较好
   > 保护DB的所有场景，都可以使用熔断、限流、降级。
5. 热key和大key的优化？
   - 参考[热key和大key](https://cloud.tencent.com/document/product/239/89468)，[优化缓存架构](https://www.51cto.com/article/596918.html)。他们都可能会造成集群内CPU、内存使用不均，以及网络带宽占用不均的问题，而且随着访问量的增加，逐渐拖累集群到完全宕机。
   - 对于大key，应当解决业务上的使用不当，对key成员进行合理的拆分，避免出现大key
   - 对于热key，可以引入二级缓存，加载到服务的本地缓存中。也可以对热key进行备份，分散到多个redis机器上，另外也需要对redis 访问进行一定的限流控制。另外重点在于对热key的监控，可以通过引入第三方SDK（本地缓存）的方式，或者使用流式计算（抓包评估）的方式。
6. redis有乱序问题吗？为什么不用多线程？
   - 有乱序问题，可以用事务。redis是内存数据库，内存的处理速度已经很快，而且每个命令不仅仅是读写某个key的对象，还有很多全局数据（比如：服务器状态、统计、内存分配等等），这些全局数据会让线程竞争，而且多线程也有额外的线程切换成本，使用多线程反而降低了效率。Redis虽然没有使用多线程，但是使用了IO多路复用技术，在处理请求方面速度还是很快的。
7. redis有那些部署模式，有什么区别？
   - 主从模式（需要主从同步），一般读写分离
   - 哨兵模式，在主从模式中，主节点的健康情况，需要引入额外的设计来确保，哨兵模式下增加了一个哨兵集群，用于检测主节点健康，并负责主节点选举。哨兵节点也会主动发送info魔灵来获取最新的Redis集群拓扑结构。
   - 集群模式：官方实现的高可用方案，Redis Cluster + Master + Slave。是一种去中心化模式。支持动态扩容，Cluster具备哨兵和主从切换（故障转移）能力。但相对运维复杂，只能用0号数据库。另外Redis Cluster最强大的地方是，扩充了写入的能力。哨兵模式中仍然是只有一个主库可以写入。而Redis Cluster通过引入代理，将key分到不同的槽，并映射到具体的Redis服务器上。由此提高了整体的写入能力。
8. Redis的主从同步延迟如何解决
   - 使用info指令监控主从同步情况，或者使用另外的客户端监控。在必要的时候发出警报，增加网络带宽，增加主从同步线程，换更强的电脑。
9. Redis实现分布式锁有那些方案
  - 从setnx、到set加nx参数、再到lua，都会有一些问题（主要是锁是否能完美设置过期）。注意这些方案中，value都应当具备唯一性，这样才能确定当前的锁是否是自己上的。比较好的方案可以参考Redisson框架，加锁后使用守护进程，定期查看线程是否完成业务，如果没有完成，再用expire指令延长锁的过期时间。如果应用在Redis集群中，还需要再加入分布一致性的机制（Redlock），单独建立一个多个redis（大家都是master）的集群。避免传统主从复制模式下，单一redis master挂掉之后，未完成锁数据主从同步的节点升级为master，破坏锁的安全性。这些也有Redisson提供支持。
  - 参考[7种Redis分布式锁方案](https://juejin.cn/post/6936956908007850014)
10. Redis支持事务吗？
   - 支持，但是不是传统意义上的事务。它的事务支持隔离性（事务执行期间不会被其他指令打断）。但并不保证持久性（显然）、一致性（因为没有回滚机制，执行前后的数据状态可能被打破）以及原子性。
   - Redis的事务由multi指令开启，插入多个指令，并由exec执行。本质上是将多个指令传递给Redis中的事务指令队列，并由exec通知服务器执行。
   - 提交指令如果有静态问题，则exec会直接失败，拒绝执行。提交的指令如果在运行期报错（内存、错误的指令和key等），则该条失败，但仍会继续执行。也正因如此，并不保证原子性，一批事务指令，可能部分成功。
   - 使用WATCH能一定程度上加强事务的安全性。在执行exec之前，如果watch的key发生变化，则该事务不再执行。
   - 如果对修改有一些特殊的需要，还可以使用Redis + Lua的方式来实现原子指令，当然这个事务的原子性也是值得思考的（看你自己的Lua脚本了）。
   - 参考[不支持原子性的 Redis 事务也叫事务吗？](https://cloud.tencent.com/developer/article/1692842)、[Redis中的原子操作(2)-redis中使用Lua脚本保证命令原子性 ](https://www.cnblogs.com/ricklz/p/16349508.html)
10. Redis有哪些线程
  - 在高版本中，Redis为了避免网络I/O带来的瓶颈，引入了专门处理发送数据的线程池。从此，Redis可以分为三个大类。主线程，处理连接、读事件，以及将各类写入事件发送到队列。后台线程（三个，分别是异步关闭、aof刷盘、定期惰性删除）。I/O线程（默认3个）。
11. Redis的混合持久化有什么优缺点
  - 在AOF重写时，会先保存一份RDB，再保存后续追加的AOF日志。混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，减低了大量数据丢失的风险。缺点是AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差。而且不兼容之前的Redis。
1. Redis Cluster中的槽为什么是16383个
  - Redis Cluster中Master扩充一般在1000个左右，16383个槽位仍然是足够使用的。另外Master节点之间通过gossip协议互相传递信息，以及发送心跳。在这个过程中会同步自己维护的槽的信息（bitmap），过大的槽数会明显提高通信时的数据量。
1. Redis的LRU和LFU的实现方式？
  - 由于常规的LRU、LFU需要额外的链表、Hash表，对Redis显然不适用。Redis使用的是近似LRU、LFU。也就是在每次随机选取的key中，用时间戳找出最久未使用（LRU）、用访问次数找出最少访问（LFU）。注意两种算法使用了同一个字段。```unsigned lru:24; ```但分别用了16位、8位。
12. 说一下MySQL的高可用架构
  - 参考[MySQL高可用]({{<relref "/content/post/ProgramDesign/design-distribution.md#MySQL">}})
11. MySQL的行锁有哪些，并发机制有哪些，以及MVCC的实现机制？
  - 行锁都是基于索引实现的，并发机制主要有LBCC（基于锁）和MVCC（基于快照读和活跃事务表）
  - 参考[MySQL记录锁、间隙锁、临键锁](https://www.cnblogs.com/LoveShare/p/17023767.html)
### 其他中间件：
1. kafka为什么读写性能可以很高？
   - pagecache的原理。按照4k一个page的方式组织buffer cache，每一个buffer cache是实际指向磁盘的一个block了，cache提高性能的方式靠预读，第一次读miss会同步读取后面的几个block，第二次读取如果没miss，那么继续异步读取后面的block（扩大一倍），第二次读取如果miss，重复同步读取（说明现在是一个随机存取的情况）
2. MQ消息乱序如何结局
   - 在上游生产者，控制发送缓冲区为1，强制按顺序发送。在下游消费者，使用单一消费者，按顺序处理。或者通过控制ID（hash），让同一系列消息进入同一个队列和消费者。
   - 另外也可以通过服务内进行重排序。
   - 也要注意幂等，以免重复消费。
3. kafka和rocketmq的选型原因？
   - kafka是生产者、消费者、Kafka集群（Broker），基于Topic和Partition。每个Topic可以有多个Partition，一个Partition就是一个文件夹。Partition会在多个Broker节点上复制（形成replica），保证数据一致性和高可用。
   - RocketMQ架构稍微复杂，有NameServer集群（管理Broker）、Broker、生产者/消费者。Nameserver负责服务注册和发现。RocketMQ也是基于Topic和Partition的数据模型（叫做MessageQueue），但它采用了一种主从复制的机制，确保了数据的高可用性和容错性。
   - Kafka吞吐量更高、RocketMQ延迟稍低。RocketMQ通过采用Zero Copy技术和缓存池技术来降低延迟，而Kafka则通过批量发送和异步处理的方式来提高吞吐量，但相应的会增加一定的延迟。而且RocketMQ是有推送模式的（虽然是包装了pull的本地线程），也会稍微降低延迟。
   - Kafka使用分布式协调机制，确保消息在生产者/消费者之间的顺序，RocketMQ则需要Producer进行消息排序，一定程度上影响性能。
   - Kafka消息事务不如RocketMQ。Kafka的消息事务需要自行实现。而RocketMQ应用本地事务和发送消息操作可以被定义到全局事务中
   - Kafka的topic/partition模型，会导致其不适合于过多topic的场合。顺序读写会变成随机读写。RocketMQ更适合此类场景。RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。而Kafka采用的是独立型的存储结构，每个队列一个文件。单一的混合日志文件并不能降低延迟。RocketMQ的具体做法是，使用Broker端的后台服务线程ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据（虽然是随机，但是随机批量读取是好于Kafka的随机写入的）。ConsumeQueue是消息的逻辑队列，相当于字典的目录，用来指定消息在物理文件commitLog上的位置。其中包含了这个MessageQueue在CommitLog中的起始物理位置偏移量offset，消息实体内容的大小和Message Tag的哈希值。对于这两个文件再进一步使用PageCache和MMap文件映射，提高响应速度。
   - 参考[kafka和rocketmq区别对比](https://www.cnblogs.com/liran123/p/17362481.html)、[RocketMQ核心原理](https://segmentfault.com/a/1190000040922513)、[RocketMQ的消息存储基本介绍](https://www.cnblogs.com/duanxz/p/5020398.html)
4. RocketMQ的消费顺序一致性如何保证：
  - 生产侧：在提交时有一个MessageQueueSelector，输入是可用MessageQueue，投递消息和附加参数，可以根据需要实现相应的逻辑，返回想要投递的MessageQueue。对于需要保持顺序性的业务消息，可以通过Hash等方式，将他们分配到同一个MessageQueue。
  - 消费侧：广播模式（一个消息投递到多个消费者）、集群模式（一个消息最多投递到一个消费者）。集群模式中通过AllocateMessageQueueStrategy接口，对于给定的消费者分组、消息队列列表、消费者列表，决定消费者和消费队列的对应关系。
  - 参考[《深入理解RocketMQ》- MQ消息的投递机制](https://cloud.tencent.com/developer/article/1443812)
  > 在不需要考虑顺序性的情况下，可以做很多优化，比如选择就近的机房，选择延迟最低的消费者、MessageQueue。
1. 什么是RocketMQ支持的事务消息？
  - 在一些应用场景下，生产者向消息队列上传消息也需要引入一个事务，此时可以提交一个半提交消息，并继续完成一些本地事务，如果本地事务成功，则正式提交消息，允许下游消费
  - 参考[RocketMQ官方文档：事务消息](https://rocketmq.apache.org/zh/docs/featureBehavior/04transactionmessage)
### 操作系统：
1. 什么是进程优先级反转？
   - 高、中、低优先级在高等待低时，出现的中先运行的情况，解决方法：优先级继承，高等待低时，将低优先级提高优先级，先执行，之后再恢复；优先级天花板：当进程申请某项共享资源时，都直接默认将所有可以访问到该资源的任务优先级提到最高，简单粗暴，等执行结束再恢复。
2. 虚拟内存的一次完整访问过程？
   - 每个进程都有自己的一个页表，页表的起始地址放在进程的PCB中，当某个进程运行时，将该起始地址放在页表基址寄存器中（PTBR）。该地址是物理地址。
   - 以32位机器使用两级页表为例，从PTBR中获取页表基址，加载的是一级页表，也就是页目录PGD（Page Global Directory），此后用逻辑地址前10位，索引到页目录项，再加载对应的二级页表PTE（Page Table Entry），最后用中间十位索引到页表项，加载对应页表。最后加上页内偏移就访问到了实际的内存位置。
3. 内存碎片的产生原因？
   - 内部碎片，没有完全使用分配的内存，外部碎片，未分配的连续内存区域太小，无法满足分配请求。
   - 解决办法，通过分页式的虚存管理。将物理内存分别分配，大幅减少了外部碎片。
4. 信号和信号量的区别？
   - 信号是处理异步事件的一种方式，通信使用。信号量（semaphore）是同步互斥的机制，负责协调并发环境下的资源使用。
5. 管道的分类和使用限制？
   - 有命名管道和匿名管道两种。但都是单向的，一端读另一端写。
   - 无名管道pipe只在有血缘关系的进程之间使用，因为其能共享文件描述符表，是一种存在于内存的特殊文件。命名管道fifo则可以用于任意进程间通信，在磁盘上会有该文件的标志，但是仍然会使用内存存储，当内容超过大小限制时会写磁盘。
6. select、poll、epoll的区别？
   - select和poll比较接近，只是使用的描述符表结构不太一样，支持的数量有差别，fd_set / pollfd，而且每一次调用select需要把fd_set拷贝到内核空间。
   - epoll更高端，开辟一段事件空间。使用epoll_ctl注册对应的文件事件的回调，将可以交给用户处理的放入ready队列。epoll_wait内取出一个可用的，并使用内存映射mmap拷贝到用户空间。
7. CAS的原理？是悲观锁还是乐观锁？二者优缺点
   - 通过CPU的CAS指令、内存总线锁、缓存锁MESI协议共同保证。是乐观锁
   - 无法解决ABA问题，自旋时有CPU开销，只能保障单个变量
1. 内核对象资源是什么？
   - 操作系统内核需要维护的一些对象，比如进程、线程、信号量、文件描述符，这些内容可能在不同的内核模块、用户进程中都有引用，内核使用引用计数来维护，当计数归0才会将其删除。
2. 什么时候会发生栈溢出？
   - 局部数组过大、递归层数过多、指针/数组越界。
3. 硬链接和软连接的区别
  - 硬链接是创建新的目录项指向同一个文件的inode
  - 软链接是创建新的inode，指向一个保存目标文件路径的文件
1. 页表存储在用户空间还是内核空间，在使用时是否需要陷入内核态
  - 存储在内核空间，但是普通的访问由MMU硬件完成，不需要陷入内核态，只有缺页中断时需要陷入
  - 参考[知乎：页表到底是保存在内核空间中还是用户空间中？](https://www.zhihu.com/question/493153133)
1. Linux操作系统提供哪些同步机制
  - 原子操作、读写信号量、spinlock、大内核锁（已废弃）、读写锁、大读者锁（已废弃）、RCU锁（类似双缓冲区）、顺序所（写优先，读时不上锁，如果seq id发生变化，重新读取）
  - 参考[一文搞懂Linux内核同步机制原理与实现(上篇)](https://zhuanlan.zhihu.com/p/464759089)、[(下篇)](https://zhuanlan.zhihu.com/p/464761211)
1. 什么是写时拷贝？
  - Linux在创建子进程时，会将地址空间和子进程进行共享（通过复制页表的方式），如果后续不进行重新映射的话，那么此时子进程可以以只读的方式直接使用原先的内存中的数据。但如果父进程此时修改了，那么系统会为子进程单独复制一份并修改页表（物理内存）。注意写时拷贝技术只是降低了在需要共享数据情况下，创建子进程的延迟（避免拷贝全部数据），但这个延迟只是均摊到了后续的每一次修改中。整体来看吞吐率并不一定上升。
1. 消息队列和共享内存的区别？
  - 共享内存拷贝次数少，效率高，适合大量数据，但需要额外加锁保证安全。消息队列可以点对点也可以广播，不需要考虑并发安全，拷贝次数多，适合有顺序性的处理场景。
  - 参考[消息队列和共享内存的区别](https://juejin.cn/s/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%92%8C%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84%E5%8C%BA%E5%88%AB)
1. 共享内存mmap和shmget的区别？
  - mmap的设计并不完全是为了共享内存，更多的是给出一个通过内存读写操作文件内容的方式。因此其可用的大小也更大，可以超过主存的大小。mmap下，各进程映射文件的相同部分可以共享内存。
  - shmget是对内存的共享，因此其大小不可能超过内存。而且在机器挂掉时会丢失数据。
1. 消息队列和管道的区别？
  - 对匿名管道（要求进程之间有父子关系）来说，消息队列提供了一种在两个不相关进程间传递数据的简单有效的方法。对命名管道（基于文件系统）来说，消息队列独立于发送和接收进程而存在，这消除了在同步命名管道的打开和关闭时可能产生的一些困难。
  - 参考[管道和消息队列的区别](https://www.jianshu.com/p/6153195b1030)
1. 信号和信号量的区别？
  - 记住英文名字，一个是signal、一个是semaphore。信号主要用于进程间的异步通信，而信号量主要用于控制多个进程对共享资源的访问。信号量是一种计数器，用来控制对多个进程/线程共享的资源进行访问。
### 系统运维
1. 如何查看线程级的CPU等资源占用情况？
  - 使用htop，或者在top中输入H
1. 如何查看进程执行历史，退出状态
  - 安装psacct工具集，使用其中的accton指令，开启进账记录，将会记录
  - 对于信号，还可以通过安装audit，开启audit服务，来统计发送的信号情况
  - 对于用户的操作执行历史，可以通过last、history来查看
1. 如何在代码中查看CPU/内存等资源的使用情况
  - 查看linux的虚拟文件系统/proc，尤其是各个PID下面的stat，即/proc/%PID/stat，里面包含了指定进程的各种资源利用信息
1. 程序CPU占用高，如何定位问题？
  - 使用perf对cpu执行情况进行采样，记录函数调用关系、调用占比等。还可以生成火焰图辅助
  - 参考[理解perf：怎么用perf聚焦热点函数？](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/%E5%8A%A0%E9%A4%9002%20%E7%90%86%E8%A7%A3perf%EF%BC%9A%E6%80%8E%E4%B9%88%E7%94%A8perf%E8%81%9A%E7%84%A6%E7%83%AD%E7%82%B9%E5%87%BD%E6%95%B0%EF%BC%9F.md)
### 数据结构
1. 散列冲突如何解决？
   - 链表法、开放寻址法（在碰撞位置向后按一定规则寻找一个空闲单元，主要的问题是删除的时候需要特殊处理，不能直接删）、再散列（碰撞时换用另一个散列函数，直到不再冲突）
2. AVL和红黑树的优缺点？
   - AVL树平衡性更高，因此查询有一定优势。但是其平衡维护时最坏的情况可能需要调整到根节点，删除操作性能一般，适合查询极为频繁，而插入删除修改很少的数据场景
   - 红黑树平衡性稍差，因此查询有一定劣势。但其平衡维护最差也是固定调整次数，删除操作性能较好，更稳定。在Linux内核、STL等多个场景下使用。

### 算法/数学题
1. 1000瓶药，1瓶有毒，会在24h时死亡，需要多少小白鼠才能在第24h的时候找出来？
  - 串行：如果不考虑第24h找到这个要求，可以用传统的查找方式，即串行的二分查找，首次让小白鼠喝500瓶，然后根据结果选择下250瓶喝哪些。
  - 并行：从题目可知只能进行一次测试，即只能通过一批死亡测出结果。实际上也可以并行的做二分。这里简化为1024瓶药，需要10个bit来表达，编号后，第一瓶是0000000000，最后一瓶是1111111111。令第i个小白鼠，喝下所有第i个bit为1的药。就能实现。下图以16瓶药为例子，说明4个老鼠如何能做到一次性检测。
      ![并行二分](/images/interview/parallel_binary_search.png)
2. 1个袋子、有100个黑球、100个白球，每次取出两个，如果颜色相同，则放回一个黑球，颜色不同，则放回一个白球，问最后剩下一个黑球的概率？
  - 看似复杂，但只要**分析一次操作的所有情况**就能进行总结：即每次操作，减少一个黑球，或者少两个白球但多一个黑球。从计算机的角度来看，这是归纳出了一个原子操作。
  - 在这个前提下，实际上很快就能发现，游戏存在两种结束情况：只要白球初始值是偶数，则袋子内最后的球数是一定可以归零的；否则最后会剩余一个白球
### 硬件
1. 什么是local apic？
  - PIC（Programmable Interrupt Controller可编程中断控制器）是一个有相当久历史的硬件，它对外负责连接外部各种容易产生中断的设备，对内和CPU相连。
  - 随着中断类型的增加和多CPU的出现，推出了更高级的APIC技术（Advanced PIC），它分为IO APIC和Local APIC两部分，前者就一个，仍然负责和外设通信，后者每个CPU内部集成一个，各个Local APIC、IO APIC一起通过系统总线相连。
  - IO APIC可以发送中断给指定的Local APIC，Local APIC之间也可以相互发送中断
  > 注意多CPU和多核心并不完全一样，多CPU指的是有多块CPU芯片，多核心则是一个CPU芯片中集成多个物理核心。服务器上经常有多路CPU。
1. x86架构的内存管理？
  - x86架构的内存管理是段页式内存，这里的段对应的是原本的分段式内存管理（程序段、数据段）、页则是代表内存分页管理，这两者结合起来就是段页式。按照从段到页的阶段，地址也分为虚拟地址、线性地址、物理地址。
  - 逻辑地址包含段选择器和偏移两个部分，用这两部分去描述符表（有全局和局部两种）中查找对应的线性地址，用线性地址查找到属于自己的页表，随后进行页式存储管理
  - 但对于不同的操作系统，也未必真的按照段页式编写内存管理部分，比如Linux就选择将所有的内存编入同一个段，也就是地址从一开始就是线性地址，完全使用分页管理
2. 分支预测的原理？
  - 静态预测，按照固定的分支预测
  - 动态预测，维护一个历史分支记录，动态改变预测
  - 还有更多的预测方式，如两级自适应、局部&全局分支预测、神经分支预测
3. 超标量、超线程技术是什么？
  - 超标量的实现：CPU的一个物理核心内部实际也有由多条流水线，往往还会结合指令乱序发射、多发射技术（有多条流水线，当然可以将没有依赖性的指令同步执行），最终达成在一个时钟周期内执行多条指令的能力
  - 超线程的实现：增加了取指器和译码器，使得能让多个线程在一定程度内共享一个CPU的资源，减少流水线的空闲
  > 其实从某个角度来说，超标量和超线程等技术，也是导致内存一致性问题的原因
### 其他
1. 大尾端是什么？如何判断？
    - 大地址在数字尾端。0x12345678，如果大地址位是0x78，则是大尾端
    - 网络续默认都是大尾端
    - 常用的CPU中，x86是小尾端、arm是大尾端
    - 另一种标准翻译是大端序（Big Endian）、小端序（Little Endian），大端序就是大尾端，小端序就是小尾端。
2. OLAP和OLTP是什么，有什么区别？
    - OLTP（on-line transaction processing）翻译为联机事务处理， OLAP（On-Line Analytical Processing）翻译为联机分析处理，从字面上来看OLTP是做事务处理，OLAP是做分析处理。从对数据库操作来看，OLTP主要是对数据的增删改，OLAP是对数据的查询统计分析。二者在技术栈、系统目标、服务对象、时间敏感度、业务阶段都有一定区别。
3. 谈谈秒杀系统的设计？
    - 核心思路就是对流量做验证、限流、拦截，必要的时候对服务进行降级，模糊查询结果。
    - 前端：提交按钮限制提交次数，参与活动必须登录，前端页面做成静态、本地缓存，避免对前端服务器产生压力
    - 网关：控制同一用户的流量，控制同一ip的流量
    - 业务：使用消息队列限制业务量，利用缓存加快查询速度，定期更新缓存数据
    - 数据库：根据流量情况，可能对数据库进行单独创建，[分库分表](https://zhuanlan.zhihu.com/p/98392844)，提升数据库处理能力。上锁、事务，保证不超卖。
4. 并行计算的模型有哪些：
    - 常见的并行计算模型有：BSP、PRAM、LogP、C3、BDM
5. 什么是熔断、限流、降级？
    - 参考[10张图带你彻底搞懂限流、熔断、服务降级](https://cloud.tencent.com/developer/article/1815254)。简单来说，限流是为了避免流量超过服务能力带来崩溃，主动进行的对流量速率加以控制的方法。熔断则是发现错误状态下，避免服务异常，比如发现某个下游服务异常，超过一定数值，就应该断开对该服务的访问。降级则是更高层的系统设计角度，在服务发生任何异常的时候，配置的一些处理策略，比如被限流时、被熔断时，以及当系统检测到服务压力，主动关闭一些非核心功能的情况。可以说限流和熔断都是降级的一种手段。
6. 谈谈悲观锁和乐观锁
  - 在不同的领域中，悲观锁和乐观锁有不同的含义。在操作系统层面，CAS代表乐观锁，可以短暂等待获得，悲观锁则是常规的重量级锁
  - 在分布式系统中，乐观锁则是指每次都尝试修改，在提交时可以通过对比快照数据，来确定是否能够提交。而悲观锁则是每次都一定要锁定再修改。
    
## 非专业内容考察
1. 兴趣爱好
1. 职业规划
1. 问自己的缺点
    - 说一些可以克服的，比如技术基础需要加强、工作经验有一定欠缺、对待工作有时过于细致影响效率、爱好有些分散的缺少拳头爱好
    - 被发现问题立刻承认，没必要遮掩
1. 一定要准备一份**英文**的自我介绍
1. 为什么从之前的公司离职
    - 技术追求、职业规划、生活工作

## 推荐阅读
1. [Github32k⭐ C/C++ 技术面试基础知识总结](https://github.com/huihut/interview)
1. [小林Coding-图解计算机基础](https://xiaolincoding.com/)
2. [小林Coding-Redis常见面试问题](https://xiaolincoding.com/redis/base/redis_interview.html)

## 参考
1. [知乎：后端都要学习什么？](https://www.zhihu.com/question/24952874/answer/518162706)
1. [MyBatis官网](https://mybatis.org/mybatis-3/zh/index.html)
1. [MySQL8.0 存储引擎综述](https://dev.mysql.com/doc/refman/8.0/en/pluggable-storage-overview.html)
1. [优先级反转](https://blog.51cto.com/u_15478392/4912194)
1. [内存访问全过程](https://blog.csdn.net/zhouzhiyao960211/article/details/106038416)
1. [操作系统——页表寻址](https://blog.csdn.net/qq_16775293/article/details/107855301)
1. [MySQL中NULL对索引的影响](https://www.jianshu.com/p/3cae3e364946)
1. [OLTP与OLAP的关系是什么？ - Kyligence的回答 - 知乎](https://www.zhihu.com/question/24110442/answer/851671343)
1. [【x86架构】内存管理](https://blog.csdn.net/jiangwei0512/article/details/63687977)
1. [理解X86的内存管理](https://www.cnblogs.com/kongchung/p/15322175.html)
1. [段式、页式内存管理以及linux采用的方案图解](https://blog.csdn.net/jinking01/article/details/107098437)
1. [知乎专栏：计算机中断体系一：历史和原理](https://zhuanlan.zhihu.com/p/26464793)
1. [APIC的那些事儿](https://www.binss.me/blog/what-is-apic/)
1. [【并发基础】CAS（Compare And Swap）操作的底层原理以及应用详解](https://blog.nowcoder.net/n/3f413b4af088415baafc159591a1a411#4.1%20%E5%A4%84%E7%90%86%E5%99%A8%E8%87%AA%E5%8A%A8%E4%BF%9D%E8%AF%81%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AD%98%E6%93%8D%E4%BD%9C%E7%9A%84%E5%8E%9F%E5%AD%90%E6%80%A7)
1. [秒杀系统设计](https://juejin.cn/post/6861749238466576397)、[【秒杀抽奖】秒杀系统设计](https://pdai.tech/md/arch/arch-example-seckill.html)、[这一次，彻底弄懂“秒杀系统”](https://www.infoq.cn/article/ypqschsrdsk8bv5nhny4)
1. [linux专题 1:page cache](https://www.jianshu.com/p/9fbabff592ff)
1. [WIKI 分支预测器](https://zh.wikipedia.org/wiki/%E5%88%86%E6%94%AF%E9%A0%90%E6%B8%AC%E5%99%A8)
1. [内核笔记（七）——内核对象（Kernel object）机制](https://developer.aliyun.com/article/1148764)
1. [并行计算模型](https://blog.csdn.net/Shockang/article/details/115987113)
1. [static_cast, dynamic_cast和reinterpret_cast的区别](https://blog.51cto.com/mingtangduyao/1832128)
1. [红黑树与AVL树，各自的优缺点总结](https://www.jianshu.com/p/37436ed14cc6)
1. [关于AVL树和红黑树的一点看法](https://zhuanlan.zhihu.com/p/93369069)
2. [去BAT，你应该要看一看的面试经验总结](https://developer.aliyun.com/article/681127)
3. [C++LinuxWebServer 2w7k的面经长文(上)](https://blog.csdn.net/qq_37457202/article/details/129790945)
4. [C++LinuxWebServer 2w7k的面经长文(上)](https://ydlin.blog.csdn.net/article/details/129791171)
5. [知乎-卢新来：高并发的一些总结](https://zhuanlan.zhihu.com/p/91168955)
6. [Leetcode——C++突击面试](https://blog.csdn.net/luanfenlian0992/article/details/118771472)