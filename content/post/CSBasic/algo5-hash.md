---
title: "算法导论其五：哈希表"
date: 2021-08-16T10:10:21+08:00
categories:
- 计算机科学与技术
- 算法
tags:
- 算法系列
- 施工中
thumbnailImagePosition: left
thumbnailImage: images/thumbnail/algorithm.jpg
math: true
---
哈希表的使用概率实在是太高太高啦，毕竟常数级的期望时间复杂度是真的诱惑。大部分语言都提供良好的哈希表数据结构。底层的原理进来了解一下呀。
<!--more-->
# 基本概念
1. 散列表（hash table）：哈希表的真正学名。提供根据关键字进行访问数据能力的一类数据结构。
2. 散列函数：即哈希函数，用于将关键字转换为散列地址，进行数据访问。
3. 关键字（key）：不同元素之间用来区分的数据字段。
4. 槽（slot）：散列表中的一个存储单元，其对应的地址叫做散列地址。
5. 装载因子（load factor）：一个能存放n个元素，具有m个槽位的散列表，其装载因子$\alpha = n / m$，$\alpha$可以小于、等于、大于1。
# 直接寻址表
&emsp;&emsp; 如果关键字的域$\mathrm{U}=\\{0,1,2....,m-1\\}$比较小，则可以让每个关键字都直接对应表中的一个下标值。这种方法实际上不需要经过散列函数，基本就是原始数组。
# 散列表
- 直接寻址法有相当明显的问题，如果域U很大，我们是不能把它全存在内存里的。而且如果数据分布并不均匀，大部分空间都将被浪费。
- 散列表做出的改进就是，利用散列函数h，将关键字域U映射到散列表的n个散列地址上，即$h:U\to \\{0,1,...,n-1\\}$。经过散列函数的映射，散列表实际上只需要管理n个大小的表空间。
- **新的问题**：不同的关键字可能被映射到同一个槽（碰撞）。需要想办法避免。
# 选择更好的散列函数
- 目标：针对输入的关键字域，提供尽量满足简单一致散列（任何元素散列到任何槽中的概率均相同，且和其他元素已被散列情况独立无关）假设的映射。
- 首先：将关键字解释为自然数。多数散列函数都需要输入的关键字域为自然数集，如果输入不是，如字符串、浮点数。需要有办法先转换为自然数。
- 除法散列法：$h(k)=k &ensp; mod &ensp; n$。$n$的选取是一门玄学，一般可选一个质数（碰撞发生概率相对更小一些）。
- 乘法散列法：$h(k)=\lfloor m(kA &ensp; mod &ensp; 1) \rfloor$。关键字$k$乘一个常数$A ( 0 < A < 1 )$，并抽出小数部分。最后用$m$乘，并对结果取整。这里说的方法是在实数域上进行运算的。
    - 实际上也有一些关于$m$、$A$等的推荐。例如Knuth建议选择$A$接近黄金分割比。而$m$为了方便计算，一般选择2的整数次幂（乘法就相当于位移运算了）。
    - 按照以上推荐，我们可以实现一个**很方便的算法**。稍微改变原有的公式。
        1. 不乘$A$，转而计算$ks$，其中$s=A \cdot 2^{w}$，$w$为计算机的位长。
            - 此时计算结果即为小数部分（高位已经溢出的部分是$mod &ensp; 1$的整数部分）。其高位即为最后乘$m$后再取整的部分。
            - 只需要进行一次乘法，而且由于$A$和$w$都已知，可以提前计算。因此只需要进行一次整数乘法，而不是浮点数乘法。
        2. 根据$m=2^{p}$，取当前结果的高$p$位。
<!-- TODO -->
- 全域散列法：
# 散列后解决碰撞
- 链接法：每一个槽内保存一个链表，再存储具体数据元素。
    - 有围绕装载因子的严格证明，在简单一致散列前提，和在槽数和元素数成正比的情况下，能保证操作时间满足平均$\mathrm{O}(1)$。
    - 因为只需要成正比关系，因此装载因子$\alpha$允许超过1。
- 开放散列法：插入时用一个散列函数序列，依次探查散列表，直到找到一个空槽。
    - 好理解的来说就是：一次hash找不到空位置，再重新hash一次，重复直到能找到位置。
    - 链接法的问题在于，每一个记录多了一个和自己无关的链接地址，在有些情况下，这浪费的空间实在是没有必要。
    - 现在我们的散列函数，还需要包含一项代表当前探查号的参数，即$h:U\times\\{0,1,...,m-1\\} \to \\{0,1,...,m-1\\}$，其中$m$还是槽的数量。
    - 可用的探查方式($\acute{h}$代表原散列函数)
        1. 线性探查：$h(k,i)=(\acute{h}(k)+i) mod &ensp; m$，即从第一次探查的槽位置，逐个向后查找空槽。很容易因为**群集现象**（连续占用的槽越来越多）导致性能降低。
        2. 二次探查：$h(k,i)=(\acute{h}(k)+c_{1}i+c_{2}i^{2}) mod &ensp; m$，即带有两个常数，以平方形式向后探查。但仍然具有**二次群集**（第一次探查结果相同的键，二次探查序列仍然相同）。而且其中$c_{1}$$c_{2}$必须仔细设置才能让整个序列都有机会探查到。
        3. 双重散列：$h(k,i)=(h_{1}(k)+ih_{2}(k)) mod &ensp; m$，其中$h_{1}$$h_{2}$是两个散列函数，需要满足和$m$的一定关系，来保证能够探查到整个序列。
    - 依然有围绕装载因子的证明，可以得出结论，装载因子为$\alpha < 1$的开放散列表中，成功探查时的期望探查次数至多为$\frac{1}{a}ln\frac{1}{1-\alpha}$。
    - 新问题：插入和查找依然很方便，但是删除操作简直要命。一般来说需要在槽上给出一个删除标记，但是这样做之后，查找时间就无法保证。因此如果需要删除操作，开放散列法并不是很好的选择。
<!-- TODO -->
- 完全散列法：
# 一点点思考
散列表虽然引入了各式各样的方法，其实本质上都是希望用空间换一些时间。我们并不希望一个散列表具有99.99%之类的装填率，因为那样会显著降低散列表的性能。实际上当你使用散列表的时候，你多多少少都会浪费一些空间的。
# 数据结构还是算法
虽然看起来散列表是一种数据结构，但是其实取散列的思想是一种非常常见的算法套路。比如当我们需要判断两个元素的内容是否完全相同时，就可以先判断其散列值是否相同，相同再在内容中逐字段深度比较，散列值不同则一定不相同。