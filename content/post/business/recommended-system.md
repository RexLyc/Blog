---
title: "学点业务：推荐系统"
date: 2024-03-18T21:37:58+08:00
categories:
- 业务
- 推荐系统
tags:
- 交叉
- 推荐系统
# thumbnailImagePosition: left
# thumbnailImage: //example.com/image.jpg
draft: true

---
本文记录推荐系统的基本组成和常见设计优化，偏向后端研发。
<!--more-->
## 基本构成
召回：
1. 准备所有推荐的内容（内容池，这个池子已经是根据用户相关的了）
2. 过滤

> 这一步是并行，可能做多种召回，一起输入到粗排

粗排：
1. 个性化打分
2. 截断

精排
1. 个性化打分
2. 截断（100个左右）

> 粗排和精排，都同样可能是并行，请求多个模型，或者请求多个

重排
1. 多样性的选择策略
2. 生成最终候选集

完成以上链路工作的就是推荐引擎，对引擎来说，最重要的输入就是三个：场景、用户、视频Item。其中
- 以用户属性来请求视频，可以看作是一个倒排索引
- 对于算法工程师，提供算子：上下文、用户信息、视频信息

里面涉及到的偏后台开发实现的一些细节
1. 索引，倒排索引
2. 曝光过滤，避免重复推荐。（布隆过滤器）
3. 模型部署方案。粗排、精排中的机器学习模型
4. 推荐模型中的大量特征存储。
   1. parameter server：[参数服务器](https://cloud.tencent.com/developer/article/1694537)
5. 如何满足实时性要求，比如10w qps

## 术语
1. 协同过滤：基于用户特征的（推送有相同爱好的用户的物品）、基于物品特征的（推送和当前物品相关的物品）
2. 冷启动：新用户、新物品
3. 背压：流式处理系统中，下游速度跟不上上游生产的速度
4. 预热
5. 召回：“召回（match）”指从全量信息集合中触发尽可能多的正确结果，
6. fid：feature-id，特征id，是推荐系统传输中最常用的内容

## 核心
### Parameter Server
参考：[深入浅出之「Parameter Server」架构](https://cloud.tencent.com/developer/article/1694537)、[Bilibili 分布式机器学习系统: Parameter Server 设计](https://www.bilibili.com/video/BV1vY4y1r71u)

参与节点：Master、Worker（机器学习训练）、Parameter Server

为什么MapReduce不能完成这种工作？MapReduce是同步通信。但机器学习应用中，数据同步量是非常大的，异步通信是很重要的。

通信层设计：
- 训练部分框架需要准备的接口：准备数据（权重和输入数据）、前向计算、反向求导、更新权重
- 那么对应的，参数服务器需要提供的接口：提供数据的pull、push功能

工作流程设计：
- worker的工作流程：接收上层计算任务调度，拉取PS上提供的权重参数，在本地计算，并将梯度更新推送给PS。这里有一个异步造成的收敛问题，如果上一轮的反向传播未完成，下一轮就已经开始，收敛会变慢，更差的情况，收敛可能错误。根据需要，框架应该能提供完全异步、完全同步（退化为MapReduce）、半同步（运行上一个迭代之后等待一段合适的时间）。
- PS的工作流程：在一次训练周期内，拿到多个worker提交的梯度，加权平均更新本地参数。
> Worker节点是无状态的

存储层设计：
- 数据分类：原始特征、中间特征、输出特征
- 存储结构：k-v存储，内存中存key-value的hashMap（一般来说，value不是数据，而是数据在磁盘上的地址），以及读数据的Cache。数据直接写磁盘持久化。内存+AOF文件。
- hash设计：减少rehash，减少内存占用，减少并发冲突。
  - 布隆过滤器，而且还需要是做过修改的布隆过滤器（计数布隆过滤器，将原先的每一个bit扩充为计数器）
  - 检测出对模型作用大的key，比如某个参数相对更多被修改
  - ring hash table：维护若干个hash table，并随时间循环滚动（第一个hash table将在第二轮开始前清空，后续以此类推不断清空并覆盖），如果是热点数据，则一定会位于某一个hash table内。
  - 也可以用多重hash
- 存储线程处理：单线程，参考redis
- 副本备份设计
  - Linux子进程fork，并在子进程内做备份。但是显然最坏情况会占用大量内存（CopyOnWrite）
  - 对磁盘添加Agent探针，读取AOF修改，并发给MQ
- 数据分片：一致性哈希
  - 分片的调整代价一般是很高昂的，如果需要提高性能，可以引入更多的副本，而不是提高分片数量
- 数据复制：
  - 扇出复制：由master节点负责控制，实现简单，缺点也很明显（单点故障和网络占用）
  - 链式复制：延迟问题
  - 训练和预估分离，训练集群是离线场景需要可读可写，预估集群是在线场景只需要只读

运维设计
- 难点：多机器/多集群/多任务/多模型/多租户，在线/近线/离线 等复杂场景。
- ML Ops，面向终态的检测（保证设计需求，检测是否满足最终状态，并调整）

### 候选/特征/召回
参考[推荐系统-架构综述02: 候选/特征/召回](https://www.bilibili.com/video/BV1NW4y1j7uA)

从流程上看，一个推荐内容输入（文章/物品/视频）的处理流程
1. 审核、转码
2. HBase存储、Flink提取特征
3. 构建倒排索引（从特征获取内容）、正排索引（从内容获取特征）
4. 召回系统：目标是快速返回top-k的内容，本质是检索系统
   - 基于用户兴趣和item特征。比如可以通过向量检索（使用不同的向量距离算法）、余弦相似度，计算二者相似度。
   - 多路并行召回：向量检索返回、高热数据、关注作者等等
   - 召回合并：蛇形合并，再考虑正拍索引过滤（涉及某些内容的，不能召回）

### 排序/训练/重排/消重
这一部分的目标就是将召回提供的数据，进行进一步的排序，以期待提高用户的满意度。其中
- 粗排：简单模型快速筛选
- 精排：用效果好但是慢的
- 重排（混排）：精排后的结果并不是最好的，比如相同作者，或者内容雷同的内容，不能放在相邻的顺序，而且还需要向其中插入商业化的内容（广告、第三方等）
- 消重：召回内容的更新实时性不一定足够，需要在尽量接近用户侧再做一次消重

### 流程调度框架
这里以kubeflow为例，一个流程调度框架提供了如下的功能
1. Python SDK：提供Kubeflow的Python接口，定义Pipeline并转换为K8s的yaml配置
2. DSL编译器
3. Pipeline服务：运行pipeline
4. K8s自定义资源
5. 工作流控制器
6. 元数据和输出存储
7. 持久化代理
8. Pipeline Web服务器
9. 执行计算所需的核心组件：Kubeflow中的Seldon Core，用于在k8s上大规模部署机器学习模型

KFServing：一个AI模型上线部署的微服务框架

## 优化点
### 通信优化
1. 对参数进行压缩，参数中往往有大量的0。
2. 批处理
3. P2P分发


### 索引
基础方案，实时+全量+分布式协调。

### mmap


## 其他
### 分层A/B实验

## 应用场景
1. 什么时候需要推荐系统？
   1. 用户缺乏明确目的
   2. 长尾信息缺少流量
   > 相反，很强的工具属性的软件，就不一定需要做推荐系统
2. 

## 参考
1. [知乎-卢新来：​倒排索引](https://zhuanlan.zhihu.com/p/338487179)
2. [知乎-卢新来：推荐系统架构的“三足鼎立”](https://zhuanlan.zhihu.com/p/92743599)
3. [B站强推！王树森老师亲授推荐系统！](https://www.bilibili.com/video/BV1jh411A7WZ)
4. [百亿数据，毫秒级返回，如何设计？--浅谈实时索引构建之道](https://www.cnblogs.com/xiekun/p/14613073.html)
5. [美团广告实时索引的设计与实现](https://tech.meituan.com/2018/05/11/adp-rtidx-ls.html)
6. [智能后端和架构-推荐系统](https://www.yijiyong.com/ac/rsintro/01-intro.html)
